{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4558ae65",
   "metadata": {},
   "source": [
    "## Gradient Descent istifadÉ™ edÉ™n modellÉ™r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744d89e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Xeyr, bÃ¼tÃ¼n bu modellÉ™r **Gradient Descent (GD)** istifadÉ™ etmir. GÉ™lin ayrÄ±-ayrÄ±lÄ±qda baxaq:  \n",
    "\n",
    "### **Gradient Descent istifadÉ™ edÉ™n modellÉ™r:**\n",
    "1. **Linear Regression** â€“ BÉ™li, bÃ¶yÃ¼k datasetlÉ™rdÉ™ GD tez-tez istifadÉ™ olunur. Amma kiÃ§ik datasetlÉ™rdÉ™ normal tÉ™nliklÉ™rlÉ™ ($Normal\\ Equation$) hÉ™ll edilÉ™ bilÉ™r.  \n",
    "2. **Logistic Regression** â€“ BÉ™li, ehtimal funksiyasÄ±nÄ± maksimum etmÉ™k Ã¼Ã§Ã¼n GD istifadÉ™ olunur.  \n",
    "3. **Support Vector Machine (SVM)** â€“ BÉ™li, xÃ¼susÉ™n dÉ™ `$SGDClassifier$` (Stochastic Gradient Descent) istifadÉ™ edilÉ™ndÉ™ GD tÉ™tbiq olunur. Amma É™nÉ™nÉ™vi SVM-lÉ™r **Quadratic Programming** Ã¼sulu ilÉ™ hÉ™ll olunur.\n",
    "\n",
    "### **Gradient Descent istifadÉ™ etmÉ™yÉ™n modellÉ™r:**\n",
    "4. **NaÃ¯ve Bayes** â€“ Xeyr, Ã§Ã¼nki Bayes teoreminÉ™ É™saslanÄ±r vÉ™ qapalÄ± formada (analitik hÉ™ll) hesablanÄ±r.  \n",
    "5. **Decision Tree (Design Tree)** â€“ Xeyr, Ã§Ã¼nki aÄŸac qurulmasÄ± iterativ bÃ¶lmÉ™lÉ™rÉ™ (splitting) É™saslanÄ±r, GD istifadÉ™ etmir.  \n",
    "6. **Random Forest** â€“ Xeyr, Ã§Ã¼nki bir neÃ§É™ Decision Tree modelinin birlÉ™ÅŸmÉ™sindÉ™n ibarÉ™tdir.  \n",
    "7. **Bayesian Methods** (Bayesian Logistic Regression vÉ™ s.) â€“ ÆsasÉ™n Bayes qaydalarÄ±na vÉ™ ehtimal paylanmalarÄ±na É™saslanÄ±r, GD istifadÉ™ etmir. Amma bÉ™zÉ™n optimallaÅŸdÄ±rma Ã¼Ã§Ã¼n variational inference Ã¼sullarÄ±nda GD tÉ™tbiq oluna bilÉ™r.\n",
    "\n",
    "**QÄ±sa NÉ™ticÉ™:**  \n",
    "- **Gradient Descent É™sasÉ™n optimallaÅŸdÄ±rma tÉ™lÉ™b edÉ™n modellÉ™rdÉ™ istifadÉ™ olunur.**  \n",
    "- **Tree-based (Decision Tree, Random Forest) vÉ™ NaÃ¯ve Bayes modellÉ™rindÉ™ isÉ™ Gradient Descent tÉ™lÉ™b olunmur.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90670f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa3677c",
   "metadata": {},
   "source": [
    "## Burada Gradient Descent harada iÅŸlÉ™yir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21879d7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "BÉ™li, `LogisticRegression` modeli **Gradient Descent (GD) vÉ™ digÉ™r optimallaÅŸdÄ±rma metodlarÄ±ndan** istifadÉ™ edÉ™ bilÉ™r. Scikit-learn kitabxanasÄ±nda `LogisticRegression` modelinin hÉ™lli Ã¼Ã§Ã¼n mÃ¼xtÉ™lif optimallaÅŸdÄ±rma alqoritmlÉ™ri mÃ¶vcuddur.  \n",
    "\n",
    "### **Gradient Descent hansÄ± hallarda istifadÉ™ olunur?**\n",
    "`LogisticRegression` modelindÉ™ **solver (hÉ™ll metodu) seÃ§iminÉ™ gÃ¶rÉ™** GD istifadÉ™ edilÉ™ vÉ™ ya edilmÉ™yÉ™ bilÉ™r.  \n",
    "- **`solver='liblinear'`** â€“ **GD istifadÉ™ etmir**, Ã§Ã¼nki bu, kiÃ§ik datasetlÉ™r Ã¼Ã§Ã¼n $Coordinate\\ Descent$ metodundan istifadÉ™ edir.  \n",
    "- **`solver='newton-cg'`, `solver='lbfgs'`, `solver='sag'`, `solver='saga'`** â€“ Bunlar iterativ optimallaÅŸdÄ±rma Ã¼sullarÄ±dÄ±r, **specially `sag` vÉ™ `saga` Stochastic Gradient Descent (SGD) istifadÉ™ edir.**  \n",
    "\n",
    "### **Kod nÃ¼munÉ™si â€“ `saga` solver ilÉ™ Gradient Descent istifadÉ™ edÉ™k**  \n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dummy dataset yaradaq\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression modelini SGD É™saslÄ± hÉ™ll edÉ™k\n",
    "model = LogisticRegression(solver='saga', max_iter=500, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Modelin tÉ™xminlÉ™rini Ã§ap edÉ™k\n",
    "print(\"Model Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "```\n",
    "\n",
    "### **Burada Gradient Descent harada iÅŸlÉ™yir?**\n",
    "- `solver='saga'` â†’ **Stochastic Average Gradient Descent (SAGA) metodunu istifadÉ™ edir**.  \n",
    "- `max_iter=500` â†’ **GD iterasiyalarÄ±nÄ±n maksimum sayÄ±nÄ± tÉ™yin edir**.  \n",
    "- `fit(X_train, y_train)` â†’ **Burada iterativ olaraq Gradient Descent iÅŸlÉ™yir vÉ™ modelin parametrlÉ™ri yenilÉ™nir**.\n",
    "\n",
    "ÆgÉ™r daha kiÃ§ik datasetlÉ™rlÉ™ iÅŸlÉ™yirsinizsÉ™, `liblinear` solverini istifadÉ™ etmÉ™k daha mÉ™qsÉ™dÉ™uyÄŸundur. Amma bÃ¶yÃ¼k datasetlÉ™rdÉ™ **GD É™saslÄ± `saga` vÉ™ `sag`** solverlÉ™ri daha effektiv iÅŸlÉ™yir.\n",
    "\n",
    "**NÉ™ticÉ™:**  \n",
    "BÉ™li, **Logistic Regression modelindÉ™ `sag` vÉ™ `saga` solverlÉ™ri Gradient Descent istifadÉ™ edir**. Ancaq default solver `lbfgs` olduÄŸuna gÃ¶rÉ™, bÉ™zi hallarda GD É™vÉ™zinÉ™ ikinci dÉ™rÉ™cÉ™li metodlar ($quasi\\text{-}Newton$ metodlarÄ±) istifadÉ™ olunur.\n",
    "\n",
    "--- \n",
    "\n",
    "ÆlavÉ™ istÉ™klÉ™rin olsa, hÉ™miÅŸÉ™ burdayam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aeb5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c6914ae",
   "metadata": {},
   "source": [
    "## Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52510edf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**`solver`** â€“ `LogisticRegression` modelindÉ™ **optimallaÅŸdÄ±rma alqoritmini (itÉ™rativ minimizasiya metodunu) seÃ§mÉ™k Ã¼Ã§Ã¼n** istifadÉ™ olunan parametrdir. Bu, modelin **maksimum ehtimallÄ±q funksiyasÄ±nÄ± optimallaÅŸdÄ±rmaq Ã¼Ã§Ã¼n** hansÄ± Ã¼sulu tÉ™tbiq edÉ™cÉ™yini mÃ¼É™yyÉ™n edir.  \n",
    "\n",
    "### **Scikit-learn-dÉ™ mÃ¶vcud olan solver-lÉ™r vÉ™ onlarÄ±n istifadÉ™si**  \n",
    "\n",
    "| **Solver**     | **XÃ¼susiyyÉ™tlÉ™ri** | **Gradient Descent istifadÉ™ edir?** |  \n",
    "|--------------|--------------------|--------------------------|  \n",
    "| `liblinear`  | KiÃ§ik datasetlÉ™r Ã¼Ã§Ã¼n idealdÄ±r, L1 vÉ™ L2 regularization dÉ™stÉ™klÉ™yir. | âŒ (Coordinate Descent istifadÉ™ edir) |  \n",
    "| `lbfgs`      | Newton É™saslÄ± metod, Ã§oxdÉ™rÉ™cÉ™li problemlÉ™rdÉ™ yaxÅŸÄ± iÅŸlÉ™yir. | âŒ (Quasi-Newton metodudur) |  \n",
    "| `newton-cg`  | Newtonâ€™s Conjugate Gradient metodu, L2 dÉ™stÉ™klÉ™yir. | âŒ (Ä°kinci tÉ™rtib metodudur) |  \n",
    "| `sag`        | **Stochastic Average Gradient Descent**, bÃ¶yÃ¼k datasetlÉ™r Ã¼Ã§Ã¼n effektivdir. | âœ… (GD É™saslÄ±dÄ±r) |  \n",
    "| `saga`       | **SGD-nin tÉ™kmillÉ™ÅŸdirilmiÅŸ versiyasÄ±**, hÉ™m L1, hÉ™m L2 regularization dÉ™stÉ™klÉ™yir. | âœ… (GD É™saslÄ±dÄ±r) |  \n",
    "\n",
    "### **NÉ™ticÉ™:**  \n",
    "ÆgÉ™r **Gradient Descent É™saslÄ± optimallaÅŸdÄ±rma** istÉ™yirsinizsÉ™, `solver='sag'` vÉ™ ya `solver='saga'` seÃ§mÉ™lisiniz.  \n",
    "DigÉ™r solver-lÉ™r isÉ™ ya **Newton É™saslÄ± iterativ metodlar**, ya da **Coordinate Descent** istifadÉ™ edirlÉ™r.\n",
    "\n",
    "---\n",
    "\n",
    "Bu formatlaÅŸdÄ±rma istÉ™diyin kimi oldu mu? BaÅŸqa dÉ™yiÅŸikliklÉ™r etmÉ™k istÉ™yirsÉ™nsÉ™, mÉ™nÉ™ bildirÉ™ bilÉ™rsÉ™n!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a117f78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1349be",
   "metadata": {},
   "source": [
    "## saga\tSGD-nin tÉ™kmillÉ™ÅŸdirilmiÅŸ versiyasÄ±, hÉ™m L1, hÉ™m L2 regularization dÉ™stÉ™klÉ™yir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08b8b0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ğŸ” **`saga` nÉ™dir?**\n",
    "`saga` â€“ **Gradient Descent** metodunun **tÉ™kmillÉ™ÅŸdirilmiÅŸ versiyasÄ±dÄ±r**. Æsas mÉ™qsÉ™di:  \n",
    "- **BÃ¶yÃ¼k datasetlÉ™rdÉ™** daha sÃ¼rÉ™tli vÉ™ sabit konvergensiya (nÉ™ticÉ™yÉ™ Ã§atmaq),\n",
    "- **L1 vÉ™ L2 cÉ™rimÉ™lÉ™ndirmÉ™** (regularization) Ã¼sullarÄ±nÄ± dÉ™stÉ™klÉ™mÉ™k.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ **SGD nÉ™dir?**\n",
    "**SGD (Stochastic Gradient Descent)** â€“ modelin parametrlÉ™rini optimallaÅŸdÄ±rmaq Ã¼Ã§Ã¼n istifadÉ™ edilÉ™n metoddur. Klassik GD hÉ™r dÉ™fÉ™ bÃ¼tÃ¼n dataset Ã¼zÉ™rindÉ™ iÅŸlÉ™yir, amma:\n",
    "- **SGD** hÉ™r dÉ™fÉ™ yalnÄ±z **bir nÃ¼munÉ™yÉ™** vÉ™ ya **mini-batch**-É™ baxaraq daha sÃ¼rÉ™tli irÉ™lilÉ™yir.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ `saga` necÉ™ tÉ™kmillÉ™ÅŸib?\n",
    "- `saga`, **SGD-nin zÉ™if cÉ™hÉ™tlÉ™rini** aradan qaldÄ±rmaq Ã¼Ã§Ã¼n yaradÄ±lÄ±b.\n",
    "- Daha **sÃ¼rÉ™tli konvergensiya** (yÉ™ni nÉ™ticÉ™yÉ™ daha tez Ã§atÄ±r),\n",
    "- **Stabil** vÉ™ **qÉ™rarsÄ±zlÄ±ÄŸa qarÅŸÄ± dÃ¶zÃ¼mlÃ¼dÃ¼r**.\n",
    "- **Spars (az sÄ±xlÄ±qlÄ±)** data ilÉ™ Ã§ox yaxÅŸÄ± iÅŸlÉ™yir.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… **L1 vÉ™ L2 Regularization nÉ™dir?**\n",
    "Regularization â€“ modelin **Ã§ox Ã¶yrÉ™nmÉ™sinin (overfitting)** qarÅŸÄ±sÄ±nÄ± almaq Ã¼Ã§Ã¼n tÉ™tbiq olunan texnikadÄ±r.\n",
    "\n",
    "| Regularization | Ä°zah | TÉ™siri |\n",
    "|----------------|------|--------|\n",
    "| **L1 (Lasso)** | ParametrlÉ™rin cÉ™minÉ™ cÉ™rimÉ™ É™lavÉ™ edir | BÉ™zi koeffisiyentlÉ™ri **0** edir (feature selection) |\n",
    "| **L2 (Ridge)** | ParametrlÉ™rin kvadrat cÉ™minÉ™ cÉ™rimÉ™ É™lavÉ™ edir | BÃ¼tÃ¼n koeffisiyentlÉ™ri **kiÃ§ildÉ™r**, amma 0 etmÉ™z |\n",
    "\n",
    "ğŸŸ¡ `saga` hÉ™m L1, hÉ™m dÉ™ L2 regularization-u **dÉ™stÉ™klÉ™diyi Ã¼Ã§Ã¼n Ã§ox Ã§evikdir**. MÉ™sÉ™lÉ™n:\n",
    "```python\n",
    "LogisticRegression(solver='saga', penalty='l1')  # Lasso\n",
    "LogisticRegression(solver='saga', penalty='l2')  # Ridge\n",
    "LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5)  # L1 + L2 qarÄ±ÅŸÄ±ÄŸÄ±\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ NÉ™ticÉ™:\n",
    "`saga` â€“ Gradient Descent-in **É™n gÃ¼clÃ¼ vÉ™ Ã§evik versiyalarÄ±ndan biridir**, bÃ¶yÃ¼k datasetlÉ™r vÉ™ mÃ¼xtÉ™lif regularization Ã¼sullarÄ± ilÉ™ rahat iÅŸlÉ™yir. Ona gÃ¶rÉ™ dÉ™ `scikit-learn`-dÉ™ **É™n professional seÃ§imlÉ™rdÉ™n biridir.**\n",
    "\n",
    "ÆgÉ™r istÉ™sÉ™n, L1 vÉ™ L2-nin qrafik tÉ™sirini dÉ™ gÃ¶stÉ™rÉ™ bilÉ™rÉ™m.\n",
    "\n",
    "---\n",
    "\n",
    "Bu versiya istÉ™diyin ÅŸÉ™kildÉ™ oldu mu? BaÅŸqa dÉ™yiÅŸiklik etmÉ™k istÉ™yirsÉ™nsÉ™, mÉ™nÉ™ bildirÉ™ bilÉ™rsÉ™n!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6ce07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
